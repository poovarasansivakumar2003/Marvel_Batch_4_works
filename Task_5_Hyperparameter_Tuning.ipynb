{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbPhTshZMIfnO9/MnE69pM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poovarasansivakumar2003/Marvel_Batch_4_works/blob/main/Task_5_Hyperparameter_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hyperparameter Tuning**\n",
        "Hyperparameter tuning is the process of optimizing the hyperparameters of a machine learning model to achieve the best performance on a given dataset. Hyperparameters are the parameters that are not learned during the training process and must be set before training the model, such as learning rate, number of trees, depth of trees, etc.\n",
        "\n",
        "### **Key Concepts in Hyperparameter Tuning**\n",
        "<ol>\n",
        "<li>\n",
        "\n",
        "**Hyperparameters vs. Parameters:**</li>\n",
        "<ul>\n",
        "<li>Hyperparameters are set before training (e.g., learning rate, number of estimators).</li>\n",
        "<li>Parameters are learned during training (e.g., weights in neural networks).</li>\n",
        "</ul>\n",
        "<li>\n",
        "\n",
        "**Why Tune Hyperparameters?**</li>\n",
        "<ul><li>Proper hyperparameter tuning can significantly improve model performance by finding the optimal settings that generalize well to unseen data.</li></ul>\n",
        "\n",
        "<li>\n",
        "\n",
        "**Common Hyperparameter Tuning Techniques:**</li>\n",
        "<ul>\n",
        "\n",
        "<li>\n",
        "\n",
        "**Grid Search**: Exhaustively searches over a specified parameter grid.</li>\n",
        "<li>\n",
        "\n",
        "**Random Search**: Randomly searches over a range of hyperparameters. It is more efficient than Grid Search because it does not check every combination.</li>\n",
        "<li>\n",
        "\n",
        "**Bayesian Optimization**: Uses probability to find the best hyperparameters, taking into account past evaluations.</li>\n",
        "<li>\n",
        "\n",
        "**Automated Hyperparameter Optimization (AutoML)**: Uses advanced techniques like Genetic Algorithms or Sequential Model-Based Optimization (SMBO).</li>\n",
        "<li>\n",
        "\n",
        "**Cross-Validation**: A technique to evaluate the model's performance by dividing the data into training and testing sets multiple times, ensuring the model's performance is not dependent on a specific split of the data.</li>\n",
        "</ul>\n",
        "\n",
        "### **Steps for Hyperparameter Tuning**\n",
        "<ol>\n",
        "<li>\n",
        "\n",
        "**Select the Model**: Choose an appropriate machine learning model for your problem (e.g., Random Forest, XGBoost, Neural Networks).</li>\n",
        "<li>\n",
        "\n",
        "**Choose the Dataset**: Pick a dataset that aligns with the problem (e.g., classification or regression). You can use popular datasets like the Iris dataset, Titanic dataset, or MNIST.</li>\n",
        "<li>\n",
        "\n",
        "**Define the Hyperparameter Space**: Determine the hyperparameters to tune and their respective ranges.</li>\n",
        "<li>\n",
        "\n",
        "**Choose the Tuning Method**: Select a tuning method (Grid Search, Random Search, Bayesian Optimization).</li>\n",
        "<li>\n",
        "\n",
        "**Train and Evaluate:** Use cross-validation to train and evaluate models on the chosen dataset with different hyperparameter combinations.</li>\n",
        "<li>\n",
        "\n",
        "**Select the Best Model**: Choose the model with the best performance metrics.</li>\n",
        "</ol>\n",
        "\n",
        "### **Example: Hyperparameter Tuning with Random Forest**\n",
        "We'll use the `Iris` dataset for a classification problem and apply Random Forest to demonstrate hyperparameter tuning using `GridSearchCV` from `scikit-learn`."
      ],
      "metadata": {
        "id": "eLmPDpYuG2n9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
        "\n",
        "# Train the model using GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Evaluate the model with the best hyperparameters\n",
        "best_rf = grid_search.best_estimator_\n",
        "y_pred = best_rf.predict(X_test)\n",
        "\n",
        "# Print accuracy and classification report\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9osc118XHiJO",
        "outputId": "ff6f2e3d-9d2e-4047-dff6-cc421c2855b9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
            "Best Hyperparameters: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      1.00      1.00        13\n",
            "           2       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        45\n",
            "   macro avg       1.00      1.00      1.00        45\n",
            "weighted avg       1.00      1.00      1.00        45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explanation**:\n",
        "<ol>\n",
        "<li>\n",
        "\n",
        "**Data Preparation**: Load the Iris dataset and split it into training and testing sets.</li>\n",
        "<li>\n",
        "\n",
        "**Model Selection**: Initialize a RandomForestClassifier.</li>\n",
        "<li>\n",
        "\n",
        "**Define Hyperparameter Grid**: Create a dictionary defining the hyperparameters and their possible values to tune.</li>\n",
        "<li>\n",
        "\n",
        "**Set up GridSearchCV**: Use GridSearchCV to perform an exhaustive search over the specified hyperparameter grid with cross-validation (cv=3).</li>\n",
        "<li>\n",
        "\n",
        "**Train and Find Best Model**: Train the model and find the combination of hyperparameters that yields the highest accuracy.</li>\n",
        "<li>\n",
        "\n",
        "**Evaluate the Model**: Predict and evaluate the model on the test set using the best hyperparameters.</li>\n",
        "</ol>\n",
        "\n",
        "### **Conclusion**\n",
        "Hyperparameter tuning is crucial for optimizing machine learning models. Using techniques like Grid Search, Random Search, and Bayesian Optimization, you can significantly improve the performance of your models."
      ],
      "metadata": {
        "id": "lq_oYNJQLIQP"
      }
    }
  ]
}