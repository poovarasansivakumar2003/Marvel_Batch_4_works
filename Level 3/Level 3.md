## Task 1 - Decision Tree based ID3 Algorithm
```
Understanding Basic Terminology
Understand ID3
Implement ID3 for ID3
```
> Here is my Task [ID3](https://colab.research.google.com/drive/1ktHzOXXt0UhUnQiYGx2JIyT4Yltqce8p)

---
## Task 2 - Naive Bayesian Classifier
```
Understand Naive Bayesian Classifier, watch it in action using sklearn
Implement Naive Bayesian Classifier for text classification and other applicable datasets
```
> Here is my Task [Naive Bayesian Classifier](https://colab.research.google.com/drive/1SV0jADE2StTdVPyKrhBDNtWNPZSX71Gg)

---
## Task 3 - Ensemble techniques
```
What are ensemble techniques??
Apply the ensemble techniques on the Titanic Dataset
```
> Here is my Task [Ensemble techniques](https://colab.research.google.com/drive/1TRyNLafVy0G7aVgP2J62uBZMk14Tmzq_)

---
## Task 4 - Random Forest, GBM and Xgboost
```
Random forest: Understand &amp; Implement
GBM: Understand &amp; Implement
Xboost: Understand &amp; Implement
```
> Here is my Task [Random Forest, GBM and Xgboost](https://colab.research.google.com/drive/1KIUj6zMK-976B7FucVdeW0pzGSH4Q3X6?usp=sharing)

---
## Task 5 - Hyperparameter Tuning
```
Understanding
Pick a suitable problem (and dataset) and train a model to fit the problem
Tune the hyperparameters of the model to increase accuracy
```
> Here is my task [Hyperparameter Tuning](https://colab.research.google.com/drive/1GvlaPz4GfBnrPBLjmhYB-vnjqDl_eev5?usp=sharing)

---
## Task 6 : Image Classification using KMeans Clustering
```
Understanding K Means Clustering:
Classify a given set of images into a given number of categories using KMeans Clustering using MNIST dataset
```
> Here is my task [Image Classification using KMeans Clustering](https://colab.research.google.com/drive/1FvdLZRL2MbAuS6LUmMEXk6LHSjtt8Rc9?usp=sharing)

---
## Task 7: Anomaly Detection
```
Anomaly detection is a way to detect erroneous data points in a stream, by looking at statistical differences. Anomaly detection can be done through unsupervised or supervised learning methods.
```
> Here is my task [Anomaly Detection](https://colab.research.google.com/drive/1i9qmzsBs75vD9DAmgdInRrJGwETValSe?usp=sharing)

---
## Task 8: Generative AI Task Using GAN
```
Develop a generative adversarial network (GAN) model to generate realistic images of a specific category, such as faces, animals, or landscapes. Customize the GAN architecture and train it on a dataset relevant to the chosen category to produce high-quality and diverse synthetic images.
1. Outcome: Implementation and training of GAN model tailored to a specific image category.
2. Generating diverse and realistic synthetic images using the trained GAN.
3. Demonstrating understanding of GAN architecture and its applications in generative tasks
```
> Here is my task [Generative AI Task Using GAN](https://colab.research.google.com/drive/1A3G5YjmKXaCp3ZFIZjTIKMV0Xl74o1J0)

---
## Task 9: PDF Query Using LangChain
```
Utilize LangChain, a natural language processing framework, to extract relevant information from PDF documents based on user queries. Develop a system that can interpret user queries, process PDF documents, and retrieve relevant sections or excerpts using language understanding techniques.

Task Outcomes:

1. Development of a PDF query system using LangChain.
2. Implementation of PDF parsing and text extraction functionality.
3. Integration of natural language processing techniques for query interpretation.
4. Testing and validation of the system with various PDF documents and queries.
5. Documentation of system architecture, functionality, and usage guidelines.
```
> Here is my task [PDF Query Using LangChain]()

---
## Task 10: Table Analysis Using PaddleOCR
```
Employ PaddleOCR, an Optical Character Recognition (OCR) toolkit, to extract and analyze tabular data from images or scanned documents. Develop a pipeline that can accurately detect tables, extract data, and perform analysis such as statistical computations or data visualization.

Task Outcomes:

1. Implementation of a table detection and extraction pipeline using PaddleOCR.
2. Development of algorithms for tabular data analysis, including statistical computations.
3. Integration of data visualization techniques to represent extracted data.
4. Evaluation of pipeline accuracy and performance on various image datasets.
5. Documentation of the process, including code, methodologies, and results.
```
> Here is my task [Table Analysis Using PaddleOCR]()
