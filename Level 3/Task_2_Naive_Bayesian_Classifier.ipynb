{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hxodc_Dt92QR"
      ],
      "authorship_tag": "ABX9TyNY7TkOfq7mxQaWYPuvj7t3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poovarasansivakumar2003/Marvel_Batch_4_works/blob/main/Task_2_Naive_Bayesian_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayesian Classifier:\n",
        "\n",
        "##Introduction\n",
        "The Naive Bayesian Classifier is a probabilistic machine learning model used for classification tasks. It is based on **Bayes' Theorem** and assumes that the features are conditionally independent given the class. Despite this \"naive\" assumption, the classifier often performs surprisingly well in practice, especially for text classification tasks such as spam detection and sentiment analysis.\n",
        "\n",
        "##Key Concepts\n",
        "**Bayes' Theorem**: The foundation of the Naive Bayesian Classifier is Bayes' Theorem, which calculates the posterior probability of a class given a set of features:\n",
        "where:\n",
        "\n",
        "**Conditional Independence**: The classifier assumes that the presence (or absence) of a particular feature of a class is unrelated to the presence (or absence) of any other feature.\n",
        "\n",
        "![Bayestheorem](https://miro.medium.com/v2/resize:fit:804/1*6dmvRYysiU5PwWIcHRdKVw.png)\n",
        "\n",
        "where ùëã = (ùë•1, ùë•2, ‚Ä¶, ùë•ùëõ) is a vector of features.\n",
        "\n",
        "##Types of Naive Bayes Classifiers:\n",
        "\n",
        "**Gaussian Naive Bayes**: Assumes that features follow a Gaussian distribution.\n",
        "Multinomial Naive Bayes: Used for discrete counts (e.g., text classification with word counts).\n",
        "\n",
        "**Bernoulli Naive Bayes**: Used for binary/Boolean features (e.g., text classification with binary term occurrence).\n",
        "\n",
        "##Implementation Using Scikit-Learn\n",
        "The Naive Bayesian Classifier can be easily implemented using the scikit-learn library in Python. Below is an example of using the Naive Bayes classifier for text classification.\n",
        "\n",
        "We'll use the MultinomialNB class from scikit-learn to classify text data from the 20 Newsgroups dataset."
      ],
      "metadata": {
        "id": "hxodc_Dt92QR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the dataset\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', shuffle=True)\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
        "\n",
        "# Vectorize the text data\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(newsgroups_train.data)\n",
        "X_test = vectorizer.transform(newsgroups_test.data)\n",
        "y_train = newsgroups_train.target\n",
        "y_test = newsgroups_test.target\n",
        "\n",
        "# Train the Naive Bayes classifier\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=newsgroups_test.target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0skXT9UYuNG",
        "outputId": "a701e811-3a18-46a9-f1a3-ca8a8d7f66c7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7728\n",
            "Classification Report:\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "             alt.atheism       0.79      0.77      0.78       319\n",
            "           comp.graphics       0.67      0.74      0.70       389\n",
            " comp.os.ms-windows.misc       0.20      0.00      0.01       394\n",
            "comp.sys.ibm.pc.hardware       0.56      0.77      0.65       392\n",
            "   comp.sys.mac.hardware       0.84      0.75      0.79       385\n",
            "          comp.windows.x       0.65      0.84      0.73       395\n",
            "            misc.forsale       0.93      0.65      0.77       390\n",
            "               rec.autos       0.87      0.91      0.89       396\n",
            "         rec.motorcycles       0.96      0.92      0.94       398\n",
            "      rec.sport.baseball       0.96      0.87      0.91       397\n",
            "        rec.sport.hockey       0.93      0.96      0.95       399\n",
            "               sci.crypt       0.67      0.95      0.78       396\n",
            "         sci.electronics       0.79      0.66      0.72       393\n",
            "                 sci.med       0.87      0.82      0.85       396\n",
            "               sci.space       0.83      0.89      0.86       394\n",
            "  soc.religion.christian       0.70      0.96      0.81       398\n",
            "      talk.politics.guns       0.69      0.91      0.79       364\n",
            "   talk.politics.mideast       0.85      0.94      0.89       376\n",
            "      talk.politics.misc       0.58      0.63      0.60       310\n",
            "      talk.religion.misc       0.89      0.33      0.49       251\n",
            "\n",
            "                accuracy                           0.77      7532\n",
            "               macro avg       0.76      0.76      0.75      7532\n",
            "            weighted avg       0.76      0.77      0.75      7532\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Explanation\n",
        "**Data Loading**: The 20 Newsgroups dataset is loaded using the fetch_20newsgroups function, which includes training and test subsets.\n",
        "\n",
        "**Vectorization**: The text data is converted into numerical feature vectors using CountVectorizer. This step converts the collection of text documents to a matrix of token counts.\n",
        "\n",
        "**Model Training**: The MultinomialNB classifier is trained using the training data.\n",
        "\n",
        "**Prediction**: The trained model is used to predict the labels for the test data.\n",
        "\n",
        "**Evaluation**: The performance of the classifier is evaluated using accuracy and classification report metrics."
      ],
      "metadata": {
        "id": "zqPJTPIgZNB2"
      }
    }
  ]
}
